{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4085d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import datetime\n",
    "import logging\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "sys.path.append('DeepIRT')\n",
    "sys.path.append('DeepIRT/log')\n",
    "sys.path.append('DeepIRT/data')\n",
    "sys.path.append('DeepIRT/Model')\n",
    "\n",
    "from model import DeepIRTModel\n",
    "from run import run_model\n",
    "from utils import getLogger\n",
    "from configs import ModelConfigFactory\n",
    "from load_data import DataLoader\n",
    "from Run_DeepIRT import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "976b2d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 18:51:17,610 - Deep-IRT-model - INFO - Cross Validation 1\n",
      "2023-08-13 18:51:18,498 - Deep-IRT-model - INFO - Initializing Placeholder\n",
      "2023-08-13 18:51:18,499 - Deep-IRT-model - INFO - Initializing Key and Value Memory\n",
      "2023-08-13 18:51:18,517 - Deep-IRT-model - INFO - Initializing Q and QA Embedding\n",
      "2023-08-13 18:51:18,532 - Deep-IRT-model - INFO - Initializing Embedding Lookup\n",
      "2023-08-13 18:51:18,540 - Deep-IRT-model - INFO - Initializing Influence Procedure\n",
      "D:\\Anaconda Python\\envs\\data_analytics\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2023-08-13 18:51:18,771 - Deep-IRT-model - INFO - Initializing Loss Function\n",
      "2023-08-13 18:51:19,784 - Deep-IRT-model - INFO - Memory/key_memory_matrix:0 (float32 10x10) [100, bytes: 400]\n",
      "Memory/value_memory_matrix:0 (float32 10x20) [200, bytes: 800]\n",
      "Embedding/q_embed:0 (float32 12444x10) [124440, bytes: 497760]\n",
      "Embedding/qa_embed:0 (float32 24887x20) [497740, bytes: 1990960]\n",
      "DKVMN-ValueHead/EraseOperation/weights:0 (float32 20x20) [400, bytes: 1600]\n",
      "DKVMN-ValueHead/EraseOperation/biases:0 (float32 20) [20, bytes: 80]\n",
      "DKVMN-ValueHead/AddOperation/weights:0 (float32 20x20) [400, bytes: 1600]\n",
      "DKVMN-ValueHead/AddOperation/biases:0 (float32 20) [20, bytes: 80]\n",
      "SummaryOperation/weights:0 (float32 30x10) [300, bytes: 1200]\n",
      "SummaryOperation/biases:0 (float32 10) [10, bytes: 40]\n",
      "StudentAbilityOutputLayer/weights:0 (float32 10x1) [10, bytes: 40]\n",
      "StudentAbilityOutputLayer/biases:0 (float32 1) [1, bytes: 4]\n",
      "QuestionDifficultyOutputLayer/weights:0 (float32 10x1) [10, bytes: 40]\n",
      "QuestionDifficultyOutputLayer/biases:0 (float32 1) [1, bytes: 4]\n",
      "Total size of variables: 623652 \n",
      "Total bytes of variables: 2494608 \n",
      "\n",
      "2023-08-13 18:51:19,927 - Deep-IRT-model - INFO - Reading ./DeepIRT/data/mydata\\my_data_train0.csv and ./DeepIRT/data/mydata\\my_data_valid0.csv\n",
      "2023-08-13 18:51:20,419 - Deep-IRT-model - INFO - \n",
      "[Epoch 1/1] Training result:      AUC: 58.33%\t Acc: 37.50%\t Loss: 14.3912\n",
      "[Epoch 1/1] Validation result:    AUC: 83.33%\t Acc: 87.50%\t Loss: 2.8782\n",
      "2023-08-13 18:51:20,420 - Deep-IRT-model - INFO - Model improved.\n",
      "2023-08-13 18:51:20,422 - Deep-IRT-model - INFO - Best result at epoch 1: AUC: 83.33\t Accuracy: 87.50\t Loss: 2.8782\t Valid ability: [ 0.14536141  0.11343361  0.1311849   0.02340432 -0.00626039  0.07422819\n",
      "  0.02457259  0.18884382]\n",
      "2023-08-13 18:51:20,430 - Deep-IRT-model - INFO - Cross Validation 2\n",
      "2023-08-13 18:51:20,431 - Deep-IRT-model - INFO - Initializing Placeholder\n",
      "2023-08-13 18:51:20,436 - Deep-IRT-model - INFO - Initializing Key and Value Memory\n",
      "2023-08-13 18:51:20,452 - Deep-IRT-model - INFO - Initializing Q and QA Embedding\n",
      "2023-08-13 18:51:20,468 - Deep-IRT-model - INFO - Initializing Embedding Lookup\n",
      "2023-08-13 18:51:20,476 - Deep-IRT-model - INFO - Initializing Influence Procedure\n",
      "D:\\Anaconda Python\\envs\\data_analytics\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2023-08-13 18:51:20,745 - Deep-IRT-model - INFO - Initializing Loss Function\n",
      "2023-08-13 18:51:21,600 - Deep-IRT-model - INFO - Memory/key_memory_matrix:0 (float32 10x10) [100, bytes: 400]\n",
      "Memory/value_memory_matrix:0 (float32 10x20) [200, bytes: 800]\n",
      "Embedding/q_embed:0 (float32 12444x10) [124440, bytes: 497760]\n",
      "Embedding/qa_embed:0 (float32 24887x20) [497740, bytes: 1990960]\n",
      "DKVMN-ValueHead/EraseOperation/weights:0 (float32 20x20) [400, bytes: 1600]\n",
      "DKVMN-ValueHead/EraseOperation/biases:0 (float32 20) [20, bytes: 80]\n",
      "DKVMN-ValueHead/AddOperation/weights:0 (float32 20x20) [400, bytes: 1600]\n",
      "DKVMN-ValueHead/AddOperation/biases:0 (float32 20) [20, bytes: 80]\n",
      "SummaryOperation/weights:0 (float32 30x10) [300, bytes: 1200]\n",
      "SummaryOperation/biases:0 (float32 10) [10, bytes: 40]\n",
      "StudentAbilityOutputLayer/weights:0 (float32 10x1) [10, bytes: 40]\n",
      "StudentAbilityOutputLayer/biases:0 (float32 1) [1, bytes: 4]\n",
      "QuestionDifficultyOutputLayer/weights:0 (float32 10x1) [10, bytes: 40]\n",
      "QuestionDifficultyOutputLayer/biases:0 (float32 1) [1, bytes: 4]\n",
      "Total size of variables: 623652 \n",
      "Total bytes of variables: 2494608 \n",
      "\n",
      "2023-08-13 18:51:21,683 - Deep-IRT-model - INFO - Reading ./DeepIRT/data/mydata\\my_data_train1.csv and ./DeepIRT/data/mydata\\my_data_valid1.csv\n",
      "2023-08-13 18:51:22,239 - Deep-IRT-model - INFO - \n",
      "[Epoch 1/1] Training result:      AUC: 41.67%\t Acc: 37.50%\t Loss: 14.3912\n",
      "[Epoch 1/1] Validation result:    AUC: 66.67%\t Acc: 50.00%\t Loss: 11.5129\n",
      "2023-08-13 18:51:22,240 - Deep-IRT-model - INFO - Model improved.\n",
      "2023-08-13 18:51:22,242 - Deep-IRT-model - INFO - Best result at epoch 1: AUC: 66.67\t Accuracy: 50.00\t Loss: 11.5129\t Valid ability: [ 0.10418634 -0.12068886  0.08432831 -0.03808324  0.02113444  0.06532679\n",
      "  0.0957019   0.01136158]\n",
      "2023-08-13 18:51:22,250 - Deep-IRT-model - INFO - Cross Validation Result:\n",
      "AUC: 75.00 +/- 8.33\n",
      "Accuracy: 68.75 +/- 18.75\n",
      "Loss: 7.20 +/- 4.32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abilities = cross_validation(num_of_data=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b806a055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.14536141,  0.11343361,  0.1311849 ,  0.02340432, -0.00626039,\n",
      "        0.07422819,  0.02457259,  0.18884382], dtype=float32), array([ 0.10418634, -0.12068886,  0.08432831, -0.03808324,  0.02113444,\n",
      "        0.06532679,  0.0957019 ,  0.01136158], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(abilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51f96768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 18:21:19,890 - Deep-IRT-model - INFO - Cross Validation 1\n",
      "2023-08-13 18:21:19,891 - Deep-IRT-model - INFO - Initializing Placeholder\n",
      "2023-08-13 18:21:19,894 - Deep-IRT-model - INFO - Initializing Key and Value Memory\n",
      "2023-08-13 18:21:19,912 - Deep-IRT-model - INFO - Initializing Q and QA Embedding\n",
      "2023-08-13 18:21:19,925 - Deep-IRT-model - INFO - Initializing Embedding Lookup\n",
      "2023-08-13 18:21:19,932 - Deep-IRT-model - INFO - Initializing Influence Procedure\n",
      "D:\\Anaconda Python\\envs\\data_analytics\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2023-08-13 18:21:20,141 - Deep-IRT-model - INFO - Initializing Loss Function\n",
      "2023-08-13 18:21:21,012 - Deep-IRT-model - INFO - Memory/key_memory_matrix:0 (float32 10x10) [100, bytes: 400]\n",
      "Memory/value_memory_matrix:0 (float32 10x20) [200, bytes: 800]\n",
      "Embedding/q_embed:0 (float32 12444x10) [124440, bytes: 497760]\n",
      "Embedding/qa_embed:0 (float32 24887x20) [497740, bytes: 1990960]\n",
      "DKVMN-ValueHead/EraseOperation/weights:0 (float32 20x20) [400, bytes: 1600]\n",
      "DKVMN-ValueHead/EraseOperation/biases:0 (float32 20) [20, bytes: 80]\n",
      "DKVMN-ValueHead/AddOperation/weights:0 (float32 20x20) [400, bytes: 1600]\n",
      "DKVMN-ValueHead/AddOperation/biases:0 (float32 20) [20, bytes: 80]\n",
      "SummaryOperation/weights:0 (float32 30x10) [300, bytes: 1200]\n",
      "SummaryOperation/biases:0 (float32 10) [10, bytes: 40]\n",
      "StudentAbilityOutputLayer/weights:0 (float32 10x1) [10, bytes: 40]\n",
      "StudentAbilityOutputLayer/biases:0 (float32 1) [1, bytes: 4]\n",
      "QuestionDifficultyOutputLayer/weights:0 (float32 10x1) [10, bytes: 40]\n",
      "QuestionDifficultyOutputLayer/biases:0 (float32 1) [1, bytes: 4]\n",
      "Total size of variables: 623652 \n",
      "Total bytes of variables: 2494608 \n",
      "\n",
      "2023-08-13 18:21:21,104 - Deep-IRT-model - INFO - Reading ./DeepIRT/data/mydata\\my_data_train0.csv and ./DeepIRT/data/mydata\\my_data_valid0.csv\n",
      "2023-08-13 18:21:21,714 - Deep-IRT-model - INFO - \n",
      "[Epoch 1/1] Training result:      AUC: 83.33%\t Acc: 62.50%\t Loss: 8.6347\n",
      "[Epoch 1/1] Validation result:    AUC: 16.67%\t Acc: 62.50%\t Loss: 8.6347\n",
      "2023-08-13 18:21:21,715 - Deep-IRT-model - INFO - Model improved.\n",
      "2023-08-13 18:21:21,717 - Deep-IRT-model - INFO - Best result at epoch 1: AUC: 16.67\t Accuracy: 62.50\t Loss: 8.6347\t Valid ability: [-0.11900602  0.0578278   0.0085031   0.10747446  0.13318181  0.10914059\n",
      "  0.19019556  0.03356679]\n",
      "2023-08-13 18:21:21,729 - Deep-IRT-model - INFO - Cross Validation 2\n",
      "2023-08-13 18:21:21,731 - Deep-IRT-model - INFO - Initializing Placeholder\n",
      "2023-08-13 18:21:21,736 - Deep-IRT-model - INFO - Initializing Key and Value Memory\n",
      "2023-08-13 18:21:21,762 - Deep-IRT-model - INFO - Initializing Q and QA Embedding\n",
      "2023-08-13 18:21:21,777 - Deep-IRT-model - INFO - Initializing Embedding Lookup\n",
      "2023-08-13 18:21:21,784 - Deep-IRT-model - INFO - Initializing Influence Procedure\n",
      "D:\\Anaconda Python\\envs\\data_analytics\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2023-08-13 18:21:21,992 - Deep-IRT-model - INFO - Initializing Loss Function\n",
      "2023-08-13 18:21:22,854 - Deep-IRT-model - INFO - Memory/key_memory_matrix:0 (float32 10x10) [100, bytes: 400]\n",
      "Memory/value_memory_matrix:0 (float32 10x20) [200, bytes: 800]\n",
      "Embedding/q_embed:0 (float32 12444x10) [124440, bytes: 497760]\n",
      "Embedding/qa_embed:0 (float32 24887x20) [497740, bytes: 1990960]\n",
      "DKVMN-ValueHead/EraseOperation/weights:0 (float32 20x20) [400, bytes: 1600]\n",
      "DKVMN-ValueHead/EraseOperation/biases:0 (float32 20) [20, bytes: 80]\n",
      "DKVMN-ValueHead/AddOperation/weights:0 (float32 20x20) [400, bytes: 1600]\n",
      "DKVMN-ValueHead/AddOperation/biases:0 (float32 20) [20, bytes: 80]\n",
      "SummaryOperation/weights:0 (float32 30x10) [300, bytes: 1200]\n",
      "SummaryOperation/biases:0 (float32 10) [10, bytes: 40]\n",
      "StudentAbilityOutputLayer/weights:0 (float32 10x1) [10, bytes: 40]\n",
      "StudentAbilityOutputLayer/biases:0 (float32 1) [1, bytes: 4]\n",
      "QuestionDifficultyOutputLayer/weights:0 (float32 10x1) [10, bytes: 40]\n",
      "QuestionDifficultyOutputLayer/biases:0 (float32 1) [1, bytes: 4]\n",
      "Total size of variables: 623652 \n",
      "Total bytes of variables: 2494608 \n",
      "\n",
      "2023-08-13 18:21:22,937 - Deep-IRT-model - INFO - Reading ./DeepIRT/data/mydata\\my_data_train1.csv and ./DeepIRT/data/mydata\\my_data_valid1.csv\n",
      "2023-08-13 18:21:23,417 - Deep-IRT-model - INFO - \n",
      "[Epoch 1/1] Training result:      AUC: 50.00%\t Acc: 50.00%\t Loss: 11.5129\n",
      "[Epoch 1/1] Validation result:    AUC: 50.00%\t Acc: 62.50%\t Loss: 8.6347\n",
      "2023-08-13 18:21:23,418 - Deep-IRT-model - INFO - Model improved.\n",
      "2023-08-13 18:21:23,419 - Deep-IRT-model - INFO - Best result at epoch 1: AUC: 50.00\t Accuracy: 62.50\t Loss: 8.6347\t Valid ability: [ 0.1425624  -0.01557521 -0.01455505 -0.01708552  0.03407568  0.15030771\n",
      "  0.00372433 -0.07242937]\n",
      "2023-08-13 18:21:23,430 - Deep-IRT-model - INFO - Cross Validation Result:\n",
      "AUC: 33.33 +/- 16.67\n",
      "Accuracy: 62.50 +/- 0.00\n",
      "Loss: 8.63 +/- 0.00\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Model/results/all_result.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 252\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m abilities\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 252\u001b[0m     abilities \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 247\u001b[0m, in \u001b[0;36mcross_validation\u001b[1;34m()\u001b[0m\n\u001b[0;32m    245\u001b[0m result_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(np\u001b[38;5;241m.\u001b[39maverage(losses)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    246\u001b[0m result_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(np\u001b[38;5;241m.\u001b[39mstd(losses)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mModel/results/all_result.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    248\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(result_msg)\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m abilities\n",
      "File \u001b[1;32mD:\\Anaconda Python\\envs\\data_analytics\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Model/results/all_result.csv'"
     ]
    }
   ],
   "source": [
    "# set logger\n",
    "logger = getLogger('Deep-IRT-model')\n",
    "\n",
    "# # argument parser\n",
    "# parser = argparse.ArgumentParser()\n",
    "# # dataset can be assist2009, assist2015, statics2011, synthetic, fsai\n",
    "# parser.add_argument('--dataset', default='assist2009', \n",
    "#                     help=\"'assist2009', 'assist2015', 'statics2011', 'synthetic', 'fsai'\")\n",
    "                    \n",
    "# parser.add_argument('--save', type=bool, default=False)\n",
    "# parser.add_argument('--cpu', type=bool, default=False)\n",
    "# parser.add_argument('--n_epochs', type=int, default=None)\n",
    "# parser.add_argument('--batch_size', type=int, default=None)\n",
    "# parser.add_argument('--train', type=bool, default=None)\n",
    "# parser.add_argument('--show', type=bool, default=None)    \n",
    "# parser.add_argument('--learning_rate', type=float, default=None)\n",
    "# parser.add_argument('--max_grad_norm', type=float, default=None)\n",
    "# parser.add_argument('--use_ogive_model', type=bool, default=False)\n",
    "\n",
    "# # parameter for the dataset\n",
    "# parser.add_argument('--seq_len', type=int, default=None)\n",
    "# parser.add_argument('--n_questions', type=int, default=None)\n",
    "# parser.add_argument('--data_dir', type=str, default=None)\n",
    "# parser.add_argument('--data_name', type=str, default=None)\n",
    "\n",
    "# # parameter for the DKVMN model\n",
    "# parser.add_argument('--memory_size', type=int, default=None)\n",
    "# parser.add_argument('--key_memory_state_dim', type=int, default=None)\n",
    "# parser.add_argument('--value_memory_state_dim', type=int, default=None)\n",
    "# parser.add_argument('--summary_vector_output_dim', type=int, default=None)\n",
    "\n",
    "# _args = parser.parse_args()\n",
    "# args = ModelConfigFactory.create_model_config(_args)\n",
    "# logger.info(\"Model Config: {}\".format(args))\n",
    "# class argus:\n",
    "#     def __init__(self):\n",
    "#         # training setting\n",
    "#         self.save= False\n",
    "#         self.cpu= True\n",
    "#         self.n_epochs= 1\n",
    "#         self.batch_size= 32\n",
    "#         self.train= True\n",
    "#         self.show= True\n",
    "#         self.learning_rate= 0.003\n",
    "#         self.max_grad_norm= 10.0\n",
    "#         self.use_ogive_model= False\n",
    "#         # dataset param\n",
    "#         self.seq_len= 200\n",
    "#         self.n_questions= 110\n",
    "#         self.data_dir= './data/assist2009_updated'\n",
    "#         self.data_name= 'assist2009_updated'\n",
    "#         # DKVMN param\n",
    "#         self.memory_size= 50\n",
    "#         self.key_memory_state_dim= 50\n",
    "#         self.value_memory_state_dim= 100\n",
    "#         self.summary_vector_output_dim= 50\n",
    "#         # parameter for the SA Network and KCD network\n",
    "#         self.student_ability_layer_structure= None\n",
    "#         self.question_difficulty_layer_structure= None\n",
    "#         self.discimination_power_layer_structure= None\n",
    "#         # dataset save result\n",
    "#         self.checkpoint_dir= './Model/checkpoints/'\n",
    "#         self.result_log_dir= '/Model/results/'\n",
    "#         self.tensorboard_dir= '/Model/tensorboard/' \n",
    "\n",
    "class argus:\n",
    "    def __init__(self):\n",
    "        # training setting\n",
    "        self.dataset = 'my_data'\n",
    "        self.save= False\n",
    "        self.cpu= True\n",
    "        self.n_epochs= 1\n",
    "        self.batch_size= 1\n",
    "        self.train= True\n",
    "        self.show= True\n",
    "        self.learning_rate= 0.003\n",
    "        self.max_grad_norm= 10.0\n",
    "        self.use_ogive_model= False\n",
    "        # dataset param\n",
    "        self.seq_len= 4\n",
    "        self.n_questions= 12443\n",
    "        self.data_dir= './DeepIRT/data/mydata'\n",
    "        self.data_name= 'my_data'\n",
    "        # DKVMN param\n",
    "        self.memory_size= 10\n",
    "        self.key_memory_state_dim= 10\n",
    "        self.value_memory_state_dim= 20\n",
    "        self.summary_vector_output_dim= 10\n",
    "        # parameter for the SA Network and KCD network\n",
    "        self.student_ability_layer_structure= None\n",
    "        self.question_difficulty_layer_structure= None\n",
    "        self.discimination_power_layer_structure= None\n",
    "        # dataset save result\n",
    "        self.checkpoint_dir= './Model/checkpoints/'\n",
    "        self.result_log_dir= '/Model/results/'\n",
    "        self.tensorboard_dir= '/Model/tensorboard/'         \n",
    "        \n",
    "        \n",
    "args = argus()\n",
    "\n",
    "# print(args.save)      \n",
    "# logger.info(\"Model Config: {}\".format(args))\n",
    "        \n",
    "# create directory\n",
    "for directory in [args.checkpoint_dir, args.result_log_dir, args.tensorboard_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def train(model, train_q_data, train_qa_data, \n",
    "            valid_q_data, valid_qa_data, result_log_path, args):\n",
    "    saver = tf.compat.v1.train.Saver()\n",
    "    best_loss = 1e6\n",
    "    best_acc = 0.0\n",
    "    best_auc = 0.0\n",
    "    best_epoch = 0.0\n",
    "\n",
    "    with open(result_log_path, 'w') as f:\n",
    "        result_msg = \"{},{},{},{},{},{},{}\\n\".format(\n",
    "            'epoch', \n",
    "            'train_auc', 'train_accuracy', 'train_loss',\n",
    "            'valid_auc', 'valid_accuracy', 'valid_loss'\n",
    "        )\n",
    "        f.write(result_msg)\n",
    "    for epoch in range(args.n_epochs):\n",
    "        \n",
    "        train_loss, train_accuracy, train_auc, train_ability = run_model(\n",
    "            model, args, train_q_data, train_qa_data, mode='train'\n",
    "        )\n",
    "        valid_loss, valid_accuracy, valid_auc, valid_ability = run_model(\n",
    "            model, args, valid_q_data, valid_qa_data, mode='valid'\n",
    "        )\n",
    "\n",
    "        # add to log\n",
    "        msg = \"\\n[Epoch {}/{}] Training result:      AUC: {:.2f}%\\t Acc: {:.2f}%\\t Loss: {:.4f}\".format(\n",
    "            epoch+1, args.n_epochs, train_auc*100, train_accuracy*100, train_loss\n",
    "        )\n",
    "        msg += \"\\n[Epoch {}/{}] Validation result:    AUC: {:.2f}%\\t Acc: {:.2f}%\\t Loss: {:.4f}\".format(\n",
    "            epoch+1, args.n_epochs, valid_auc*100, valid_accuracy*100, valid_loss\n",
    "        )\n",
    "        logger.info(msg)\n",
    "\n",
    "        # write epoch result\n",
    "        with open(result_log_path, 'a') as f:\n",
    "            result_msg = \"{},{},{},{},{},{},{}\\n\".format(\n",
    "                epoch, \n",
    "                train_auc, train_accuracy, train_loss,\n",
    "                valid_auc, valid_accuracy, valid_loss\n",
    "            )\n",
    "            f.write(result_msg)\n",
    "\n",
    "        # add to tensorboard\n",
    "        tf_summary = tf.compat.v1.Summary(\n",
    "            value=[\n",
    "                tf.compat.v1.Summary.Value(tag=\"train_loss\", simple_value=train_loss),\n",
    "                tf.compat.v1.Summary.Value(tag=\"train_auc\", simple_value=train_auc),\n",
    "                tf.compat.v1.Summary.Value(tag=\"train_accuracy\", simple_value=train_accuracy),\n",
    "                tf.compat.v1.Summary.Value(tag=\"valid_loss\", simple_value=valid_loss),\n",
    "                tf.compat.v1.Summary.Value(tag=\"valid_auc\", simple_value=valid_auc),\n",
    "                tf.compat.v1.Summary.Value(tag=\"valid_accuracy\", simple_value=valid_accuracy),\n",
    "            ]\n",
    "        )\n",
    "        model.tensorboard_writer.add_summary(tf_summary, epoch)\n",
    "        \n",
    "        # save the model if the loss is lower\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_acc = valid_accuracy\n",
    "            best_auc = valid_auc\n",
    "            best_epoch = epoch+1\n",
    "\n",
    "            if args.save:\n",
    "                model_dir = \"ep{:03d}-auc{:.0f}-acc{:.0f}\".format(\n",
    "                    epoch+1, valid_auc*100, valid_accuracy*100,\n",
    "                )\n",
    "                model_name = \"Deep-IRT\"\n",
    "                save_path = os.path.join(args.checkpoint_dir, model_dir, model_name)\n",
    "                saver.save(sess=model.sess, save_path=save_path)\n",
    "\n",
    "                logger.info(\"Model improved. Save model to {}\".format(save_path))\n",
    "            else:\n",
    "                logger.info(\"Model improved.\")\n",
    "\n",
    "    # print out the final result\n",
    "    msg = \"Best result at epoch {}: AUC: {:.2f}\\t Accuracy: {:.2f}\\t Loss: {:.4f}\\t Valid ability: {}\".format(\n",
    "        best_epoch, best_auc*100, best_acc*100, best_loss, valid_ability\n",
    "    )\n",
    "    logger.info(msg)\n",
    "    return best_auc, best_acc, best_loss, valid_ability\n",
    "\n",
    "def cross_validation():\n",
    "    tf.random.set_seed(1234)\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    if args.cpu:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "    aucs, accs, losses = list(), list(), list()\n",
    "    abilities = list()\n",
    "    for i in range(2):\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        logger.info(\"Cross Validation {}\".format(i+1))\n",
    "        result_csv_path = os.path.join(args.result_log_dir, 'fold-{}-result'.format(i)+'.csv')\n",
    "\n",
    "        with tf.compat.v1.Session(config=config) as sess:\n",
    "            data_loader = DataLoader(args.n_questions, args.seq_len, ',')\n",
    "            model = DeepIRTModel(args, sess, name=\"Deep-IRT\")\n",
    "            sess.run(tf.compat.v1.global_variables_initializer())\n",
    "            if args.train:\n",
    "                train_data_path = os.path.join(args.data_dir, args.data_name+'_train{}.csv'.format(i))\n",
    "                valid_data_path = os.path.join(args.data_dir, args.data_name+'_valid{}.csv'.format(i))\n",
    "                logger.info(\"Reading {} and {}\".format(train_data_path, valid_data_path))\n",
    "\n",
    "                train_q_data, train_qa_data = data_loader.load_data(train_data_path)\n",
    "                valid_q_data, valid_qa_data = data_loader.load_data(valid_data_path)\n",
    "\n",
    "                auc, acc, loss, ability = train(\n",
    "                    model, \n",
    "                    train_q_data, train_qa_data, \n",
    "                    valid_q_data, valid_qa_data, \n",
    "                    result_log_path=result_csv_path,\n",
    "                    args=args\n",
    "                )\n",
    "\n",
    "                aucs.append(auc)\n",
    "                accs.append(acc)\n",
    "                losses.append(loss)\n",
    "                abilities.append(ability)\n",
    "                \n",
    "    cross_validation_msg = \"Cross Validation Result:\\n\"\n",
    "    cross_validation_msg += \"AUC: {:.2f} +/- {:.2f}\\n\".format(np.average(aucs)*100, np.std(aucs)*100)\n",
    "    cross_validation_msg += \"Accuracy: {:.2f} +/- {:.2f}\\n\".format(np.average(accs)*100, np.std(accs)*100)\n",
    "    cross_validation_msg += \"Loss: {:.2f} +/- {:.2f}\\n\".format(np.average(losses), np.std(losses))\n",
    "    logger.info(cross_validation_msg)\n",
    "\n",
    "    # write result\n",
    "    result_msg = datetime.datetime.now().strftime(\"%Y-%m-%dT%H%M\") + ','\n",
    "    result_msg += str(args.dataset) + ','\n",
    "    result_msg += str(args.memory_size) + ','\n",
    "    result_msg += str(args.key_memory_state_dim) + ','\n",
    "    result_msg += str(args.value_memory_state_dim) + ','\n",
    "    result_msg += str(args.summary_vector_output_dim) + ','\n",
    "    result_msg += str(np.average(aucs)*100) + ','\n",
    "    result_msg += str(np.std(aucs)*100) + ','\n",
    "    result_msg += str(np.average(accs)*100) + ','\n",
    "    result_msg += str(np.std(accs)*100) + ','\n",
    "    result_msg += str(np.average(losses)) + ','\n",
    "    result_msg += str(np.std(losses)) + '\\n'\n",
    "    with open('DeepIRT/Model/results/all_result.csv', 'a') as f:\n",
    "        f.write(result_msg)\n",
    "    \n",
    "    return abilities\n",
    "if __name__=='__main__':\n",
    "    abilities = cross_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f355415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.17799792,  0.09599354,  0.0332391 ,  0.04857728, -0.01726536,\n",
      "       -0.04803391,  0.08205722, -0.01927519], dtype=float32), array([-0.18632653, -0.06553315, -0.18330035,  0.05850279, -0.08913452,\n",
      "       -0.02749979,  0.00800037, -0.00443278], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(abilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a61f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a76ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analytics",
   "language": "python",
   "name": "data_analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
